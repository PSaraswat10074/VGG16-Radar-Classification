{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n",
      "C:\\Users\\PSaraswat\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlwin36\\lib\\site-packages\\keras\\backend\\cntk_backend.py:18: UserWarning: CNTK backend warning: GPU is not detected. CNTK's CPU version is not fully optimized,please run with GPU to get better performance.\n",
      "  'CNTK backend warning: GPU is not detected. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from os.path import join as opj\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\t\n",
    "\n",
    "#Data Aug for multi-input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('train.json')\n",
    "test = pd.read_json('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=train['is_iceberg']\n",
    "target_train=train['is_iceberg']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "X_angle=train['inc_angle']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "X_test_angle=test['inc_angle']\n",
    "\n",
    "#Generate the training data\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_band_3=(X_band_1+X_band_2)/2\n",
    "#X_band_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in train[\"inc_angle\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis]\n",
    "                          , X_band_2[:, :, :, np.newaxis]\n",
    "                         , X_band_3[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_band_test_3=(X_band_test_1+X_band_test_2)/2\n",
    "#X_band_test_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in test[\"inc_angle\"]])\n",
    "X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n",
    "                          , X_band_test_2[:, :, :, np.newaxis]\n",
    "                         , X_band_test_3[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "batch_size=64\n",
    "# Define the image transformations here\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.,\n",
    "                         height_shift_range = 0.,\n",
    "                         channel_shift_range=0,\n",
    "                         zoom_range = 0.2,\n",
    "                         rotation_range = 10)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "# Finally create generator\n",
    "def get_callbacks(filepath, patience=2):\n",
    "   es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n",
    "   msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "   return [es, msave]\n",
    "\n",
    "\n",
    "def getVggAngleModel():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train.shape[1:], classes=1)\n",
    "    x = base_model.get_layer('block5_pool').output\n",
    "    \n",
    "\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "    \n",
    "    model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "    \n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "#Using K-fold Cross Validation with Data Augmentation.\n",
    "def myAngleCV(X_train, X_angle, X_test):\n",
    "    K=3\n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=16).split(X_train, target_train))\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log=0\n",
    "    y_valid_pred_log = 0.0*target_train\n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        print('\\n===================FOLD=',j)\n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        X_holdout = X_train[test_idx]\n",
    "        Y_holdout= target_train[test_idx]\n",
    "        \n",
    "        #Angle\n",
    "        X_angle_cv=X_angle[train_idx]\n",
    "        X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "        #define file path and get callbacks\n",
    "        file_path = \"%s_aug_model_weights.hdf5\"%j\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "        gen_flow = gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "        galaxyModel= getVggAngleModel()\n",
    "        galaxyModel.fit_generator(\n",
    "                gen_flow,\n",
    "                steps_per_epoch=24,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data=([X_holdout,X_angle_hold], Y_holdout),\n",
    "                callbacks=callbacks)\n",
    "\n",
    "        #Getting the Best Model\n",
    "        galaxyModel.load_weights(filepath=file_path)\n",
    "        #Getting Training Score\n",
    "        score = galaxyModel.evaluate([X_train_cv,X_angle_cv], y_train_cv, verbose=0)\n",
    "        print('Train loss:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        #Getting Test Score\n",
    "        score = galaxyModel.evaluate([X_holdout,X_angle_hold], Y_holdout, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        #Getting validation Score.\n",
    "        pred_valid=galaxyModel.predict([X_holdout,X_angle_hold])\n",
    "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "        #Getting Test Scores\n",
    "        temp_test=galaxyModel.predict([X_test, X_test_angle])\n",
    "        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "        #Getting Train Scores\n",
    "        temp_train=galaxyModel.predict([X_train, X_angle])\n",
    "        y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "    y_test_pred_log=y_test_pred_log/K\n",
    "    y_train_pred_log=y_train_pred_log/K\n",
    "\n",
    "    print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "    print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "    return y_test_pred_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PSaraswat\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlwin36\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Composite(..., inputs=[Input('in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PSaraswat\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlwin36\\lib\\site-packages\\cntk\\core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input4\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 272s 11s/step - loss: 0.7234 - acc: 0.6035 - val_loss: 0.3642 - val_acc: 0.7963\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 233s 10s/step - loss: 0.4244 - acc: 0.7984 - val_loss: 0.3271 - val_acc: 0.8374\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 231s 10s/step - loss: 0.3587 - acc: 0.8370 - val_loss: 0.2467 - val_acc: 0.8860\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 231s 10s/step - loss: 0.2894 - acc: 0.8724 - val_loss: 0.2251 - val_acc: 0.8991\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 234s 10s/step - loss: 0.2867 - acc: 0.8790 - val_loss: 0.2250 - val_acc: 0.8972\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 245s 10s/step - loss: 0.2399 - acc: 0.8898 - val_loss: 0.2303 - val_acc: 0.8935\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 231s 10s/step - loss: 0.2511 - acc: 0.8937 - val_loss: 0.2269 - val_acc: 0.9065\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 230s 10s/step - loss: 0.2387 - acc: 0.8977 - val_loss: 0.2268 - val_acc: 0.9084\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 230s 10s/step - loss: 0.2617 - acc: 0.8952 - val_loss: 0.2103 - val_acc: 0.9065\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 231s 10s/step - loss: 0.2096 - acc: 0.9107 - val_loss: 0.2245 - val_acc: 0.8991\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 231s 10s/step - loss: 0.2013 - acc: 0.9223 - val_loss: 0.2224 - val_acc: 0.9103\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 231s 10s/step - loss: 0.2235 - acc: 0.9135 - val_loss: 0.2216 - val_acc: 0.9028\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 301s 13s/step - loss: 0.1950 - acc: 0.9192 - val_loss: 0.2206 - val_acc: 0.9047\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 230s 10s/step - loss: 0.2165 - acc: 0.9117 - val_loss: 0.2230 - val_acc: 0.9159\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 230s 10s/step - loss: 0.1973 - acc: 0.9163 - val_loss: 0.2204 - val_acc: 0.9028\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 241s 10s/step - loss: 0.1789 - acc: 0.9270 - val_loss: 0.2076 - val_acc: 0.9159\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 272s 11s/step - loss: 0.1813 - acc: 0.9239 - val_loss: 0.2172 - val_acc: 0.9103\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 273s 11s/step - loss: 0.1710 - acc: 0.9283 - val_loss: 0.2425 - val_acc: 0.9196\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 278s 12s/step - loss: 0.1754 - acc: 0.9270 - val_loss: 0.2300 - val_acc: 0.9121\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 342s 14s/step - loss: 0.1495 - acc: 0.9416 - val_loss: 0.2209 - val_acc: 0.9215\n",
      "Epoch 21/100\n",
      "11/24 [============>.................] - ETA: 2:26 - loss: 0.1573 - acc: 0.9332"
     ]
    }
   ],
   "source": [
    "preds=myAngleCV(X_train, X_angle, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=preds\n",
    "submission.to_csv('sub2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
